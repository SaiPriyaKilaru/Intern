{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f612a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium \n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.common.exceptions import NoSuchElementException"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1007544a",
   "metadata": {},
   "source": [
    "Write a python program which searches all the product under a particular product from www.amazon.in. The product to be searched will be taken as input from user. For e.g. If user input is ‘guitar’. Then search for guitars."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1eb8d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f18610d",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome()\n",
    "driver.get(\"https://www.amazon.in/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "385f2179",
   "metadata": {},
   "outputs": [],
   "source": [
    "element=driver.find_element(By.XPATH,'/html/body/div[1]/header/div/div[1]/div[2]/div/form/div[2]/div[1]/input')\n",
    "element.send_keys(input('enter item name'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad78865",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time \n",
    "search=driver.find_element(By.XPATH,'/html/body/div[1]/header/div/div[1]/div[2]/div/form/div[3]/div/span/input')\n",
    "search.click()\n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18314b13",
   "metadata": {},
   "source": [
    "2. In the above question, now scrape the following details of each product listed in first 3 pages of your search results and save it in a data frame and csv. In case if any product has less than 3 pages in search results then scrape all the products available under that product name. Details to be scraped are: \"Brand\n",
    "Name\", \"Name of the Product\", \"Price\", \"Return/Exchange\", \"Expected Delivery\", \"Availability\" and\n",
    "“Product URL”. In case, if any of the details are missing for any of the product then replace it by “-“."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0da0c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "url=[]\n",
    "start=0\n",
    "end=3\n",
    "for page in range(start,end):\n",
    "    pro_url=driver.find_elements(By.XPATH,'//a[@class=\"a-link-normal s-no-outline\"]')\n",
    "    for i in pro_url:\n",
    "        url.append(i.get_attribute('href'))\n",
    "    \n",
    "   \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b72d806",
   "metadata": {},
   "outputs": [],
   "source": [
    "next_button=driver.find_element(By.XPATH,'//a[@class=\"s-pagination-item s-pagination-next s-pagination-button s-pagination-separator\"]')  \n",
    "next_button.click()\n",
    "time.sleep(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "920ade75",
   "metadata": {},
   "outputs": [],
   "source": [
    "for pro_url in url:\n",
    "    driver.get(pro_url)\n",
    "    time.sleep(1)\n",
    "    try:\n",
    "        brand=driver.find_element(By.XPATH,'//*[@id=\"productOverview_feature_div\"]/div/table/tbody/tr[1]/td[2]/span')\n",
    "        Brand.append(brand.text)\n",
    "    except NoSuchElementException:\n",
    "        Brand.append('-')\n",
    "    try:\n",
    "        title=driver.find_element(By.XPATH,'//span[@id=\"productTitle\"]')\n",
    "        Name.append(title.text)\n",
    "    except NoSuchElementException:\n",
    "        Name.append(\"-\")\n",
    "    try:\n",
    "        price=driver.find_element(By.XPATH,'//div[@class=\"a-section a-spacing-none aok-align-center aok-relative\"]/span[3]')\n",
    "        Price.append(price.text)\n",
    "    except NoSuchElementException:\n",
    "        Price.append(\"-\")\n",
    "    try:\n",
    "        retun=driver.find_element(By.XPATH,'//div[@class=\"a-container return-policy-secondary-view-container\"]/table/tbody/tr/td[2]')\n",
    "        Return_Exchange.append(retun.text)\n",
    "    except NoSuchElementException:\n",
    "        Return_Exchange.append('_')\n",
    "        \n",
    "    try:\n",
    "        delivery=driver.find_element(By.XPATH,\"/html/body/div[2]/div/div[5]/div[3]/div[1]/div[3]/div/div[1]/div/div/div/form/div/div/div/div/div[4]/div/div[3]/div[10]/div[1]/div/div/div[1]\")\n",
    "        Exp_del.append(delivery.text)\n",
    "    except NoSuchElementException:\n",
    "        Exp_del.append(\"-\")\n",
    "    try:\n",
    "        avil=driver.find_element(By.XPATH,'/html/body/div[2]/div/div[5]/div[3]/div[1]/div[3]/div/div[1]/div/div/div/form/div/div/div/div/div[4]/div/div[5]/div/div[1]/span')\n",
    "        Availability.append(avil.text)\n",
    "    except NoSuchElementException:\n",
    "        Availability.append('-')\n",
    "    try:\n",
    "        url=driver.find_elements(By.XPATH,'//a[@class=\"a-link-normal s-no-outline\"]')\n",
    "        Product_url.append(url.text)\n",
    "    except NoSuchElementException:\n",
    "        Product_url.append(\"-\")\n",
    "        \n",
    "df=pd.DataFrame({\"Brand Name\":Brand,\"Name of the Product\":Name,\"Price\":Price,\"Return/Exchange\":Return_Exchange,\"Expected Delivery\":Exp_del,\"Availability\":Availability,\"Product URL\":product_url})\n",
    "df\n",
    "                                 \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e8807d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Brand=[]\n",
    "Name=[]\n",
    "Price=[]\n",
    "Return_Exchange=[]\n",
    "Exp_del=[]\n",
    "Availability=[]\n",
    "product_url=[]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "117a7a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "Product=pd.DataFrame({'Brand name':Brand,'Name of the product':Name,'Price':Price,'Return/Exchange':Return_Exchange,'Expected delivery':Exp_del,'Availability':Availabilityproduct_url,'Product URL':product_url})\n",
    "Product"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f1e536c",
   "metadata": {},
   "source": [
    "3. Write a python program to access the search bar and search button on images.google.com and scrape 10 images each for keywords ‘fruits’, ‘cars’ and ‘Machine Learning’, ‘Guitar’, ‘Cakes’."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ec8d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome()\n",
    "driver.get('https://images.google.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b24e9802",
   "metadata": {},
   "outputs": [],
   "source": [
    "element=driver.find_element(By.CLASS_NAME,\"gLFyf\")\n",
    "element.send_keys(input(\"enter name\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f1adf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "search=driver.find_element(By.XPATH,'/html/body/div[1]/div[3]/form/div[1]/div[1]/div[1]/button/div')\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adae5493",
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(20):\n",
    "    driver.execute_script(\"window.scrollBy(0,500)\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6122e415",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_urls=[]\n",
    "images=driver.find_elements(By.XPATH,'//img[@class=\"YQ4gaf\"]')\n",
    "for i in images:\n",
    "    source=i.get_attribute('src')\n",
    "    if source is not None:\n",
    "        if (source[0:4]==\"http\"):\n",
    "            img_urls.append(source)\n",
    "\n",
    "for i in range(len(img_urls)):\n",
    "    if i>10:\n",
    "        breakBy.XPATH"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0af900c",
   "metadata": {},
   "source": [
    "4 Write a python program to search for a smartphone(e.g.: Oneplus Nord, pixel 4A, etc.) on www.flipkart.com and scrape following details for all the search results displayed on 1st page. Details to be scraped: “Brand Name”, “Smartphone name”, “Colour”, “RAM”, “Storage(ROM)”, “Primary Camera”,\n",
    "“Secondary Camera”, “Display Size”, “Battery Capacity”, “Price”, “Product URL”. Incase if any of the details is missing then replace it by “- “. Save your results in a dataframe and CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ae7b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome()\n",
    "driver.get('https://www.flipkart.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb5f21c",
   "metadata": {},
   "outputs": [],
   "source": [
    "inpt=driver.find_element(By.CLASS_NAME,'Pke_EE')\n",
    "inpt.send_keys(input('enter item to be search'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de8d0a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "search=driver.find_element(By.CLASS_NAME,'_2iLD__')\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f05f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "Brand=[]\n",
    "Smartphone=[]\n",
    "Colour=[]\n",
    "RAM=[]\n",
    "Storage_ROM=[]\n",
    "Primary_Camera=[]\n",
    "Secondary_Camera=[]\n",
    "Display_Size=[]\n",
    "Battery_Capacity=[]\n",
    "Price=[]\n",
    "Product_URL=[]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a498cbec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "url=[]\n",
    "start=0\n",
    "end=1\n",
    "for page in range(start,end):\n",
    "    pro_url=driver.find_elements(By.CLASS_NAME,'_1fQZEK')\n",
    "    for i in pro_url:\n",
    "        url.append(i.get_attribute('href'))\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "954e312f",
   "metadata": {},
   "outputs": [],
   "source": [
    "next_button=driver.find_element(By.CLASS_NAME,'_1LKTO3')\n",
    "next_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0aed13e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "for url in Url:\n",
    "    driver.get(url)\n",
    "    time.sleep(5)\n",
    "    \n",
    "    try:\n",
    "        brand_tag=driver.find_element(By.XPATH,'//span[@class=\"B_NuCI\"]')\n",
    "        Brand.append(brand_tag.text)\n",
    "    except NoSuchElementException:\n",
    "        Brand.append('_')\n",
    "        \n",
    "    \n",
    "    \n",
    "    try:\n",
    "        name_tag=driver.find_element(By.XPATH,'//div[@class=\"_3k-BhJ\"][1]/table/tbody/tr[3]/td[2]/ul/li')\n",
    "        name.append(name_tag.text)\n",
    "    except NoSuchElementException:\n",
    "        name.append('_')    \n",
    "        \n",
    "    try:\n",
    "        colour_tag=driver.find_element(By.XPATH,'//div[@class=\"_3k-BhJ\"][1]/table/tbody/tr[4]/td[2]/ul/li')\n",
    "        colour.append(colour_tag.text)\n",
    "    except NoSuchElementException:\n",
    "        colour.append('_')\n",
    "        \n",
    "    try:\n",
    "        price_tag=driver.find_element(By.XPATH,'//div[@class=\"_30jeq3 _16Jk6d\"]')\n",
    "        price.append(price_tag.text)\n",
    "    except NoSuchElementException:\n",
    "        price.append('_')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "535a970d",
   "metadata": {},
   "outputs": [],
   "source": [
    "storage=[]\n",
    "\n",
    "storage_tag=driver.find_elements(By.XPATH,'//div[@class=\"fMghEO\"]/ul/li[1]')\n",
    "for tag in storage_tag:\n",
    "    storage.append(tag.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "601d75e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "RAM=[i.split()[0] for i in storage]\n",
    "storage_ROM=[i.split()[4] for i in storage]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "078cb425",
   "metadata": {},
   "outputs": [],
   "source": [
    "display=[]\n",
    "secondarycamera=[]\n",
    "Cameras=[]\n",
    "battery=[]\n",
    "\n",
    "\n",
    "camera_tag=driver.find_elements(By.XPATH,'//div[@class=\"fMghEO\"]/ul/li[3]')\n",
    "for tag in camera_tag:\n",
    "    result=re.findall(r'\\b([^\\(|]+)\\|', tag.text)\n",
    "    Cameras.append(result)\n",
    "            \n",
    "\n",
    "\n",
    "camera_tag=driver.find_elements(By.XPATH,'//div[@class=\"fMghEO\"]/ul/li[3]')\n",
    "for tag in camera_tag:\n",
    "    result=re.findall(r'\\|(.*)', tag.text)\n",
    "    secondarycamera.append(result)         \n",
    "\n",
    "\n",
    "display_tag=driver.find_elements(By.XPATH,'//div[@class=\"fMghEO\"]/ul/li[2]')\n",
    "for tag in display_tag:\n",
    "    display.append(tag.text)\n",
    "   \n",
    "battery_tag=driver.find_elements(By.XPATH,'//div[@class=\"fMghEO\"]/ul/li[4]')\n",
    "for tag in battery_tag:\n",
    "    battery.append(tag.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e99f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "Smartphone=pd.DataFrame({'Brand Name':Brands,'Smartphone Name':name,'Colour':colour,'RAM (GB)':RAM,'Storage(ROM)(GB)':storage_ROM,'Primary Camera':Cameras,'Secondary Camera':secondarycamera,'Display Size':display,'Battery Capacity':battery,'Price':price,'Product URL':Url})\n",
    "Smartphone"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "827b8a78",
   "metadata": {},
   "source": [
    "5. Write a program to scrap geospatial coordinates (latitude, longitude) of a city searched on google maps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a427c32d",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome()\n",
    "driver.get('https://www.google.com/maps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab507bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "inpt=driver.find_element(By.XPATH,'/html/body/div[1]/div[3]/div[8]/div[3]/div[1]/div[1]/div/div[2]/form/input')\n",
    "inpt.send_keys(input('Enter city name '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17606b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "search=driver.find_element(By.CLASS_NAME,'google-symbols')\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c85a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "url_=driver.current_url\n",
    "print('url extracted: ',url_)\n",
    "lon_lat=re.findall(r'@(.*)data',url_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd6bcc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "c=url_.split('@')[1].split(',')[0:2]\n",
    "c[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1688cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "c[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e7fb625",
   "metadata": {},
   "source": [
    "6. Write a program to scrap all the available details of best gaming laptops from digit.in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d84788",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a6cb5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('https://www.digit.in/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ba08e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "inpt=driver.find_element(By.XPATH,'/html/body/div[1]/header/div/div[1]/div/div/nav/ul/li[3]/a')\n",
    "inpt.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab29c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "bis_laptop=driver.find_element(By.XPATH,'/html/body/div[1]/div[3]/div/div[2]/div[1]/div[3]/div[5]/p/a')\n",
    "bis_laptop.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f0e33e",
   "metadata": {},
   "outputs": [],
   "source": [
    "gaming_laptop=driver.find_element(By.XPATH,'/html/body/div[1]/div[3]/div/div/div/article/div/div/div/div[2]/div/div[1]/div[3]/div[1]/div[6]/div[1]/div[1]/a')\n",
    "gaming_laptop.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf2856c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tags=driver.find_elements(By.CLASS_NAME,'rh_grid_image_3_col')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e61d2905",
   "metadata": {},
   "outputs": [],
   "source": [
    "lap_name=[]\n",
    "lap_tags=driver.find_elements(By.CLASS_NAME,'rh_grid_image_3_col')\n",
    "for i in lap_tags:\n",
    "    p=i.text\n",
    "    lap_name.append(p)\n",
    "     \n",
    "pd.DataFrame(lap_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a41cdd6",
   "metadata": {},
   "source": [
    "7. Write a python program to scrape the details for all billionaires from www.forbes.com. Details to be scrapped: “Rank”, “Name”, “Net worth”, “Age”, “Citizenship”, “Source”, “Industry”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f848bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome()\n",
    "driver.get(\"https://www.forbes.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b07e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "billion=driver.find_element(By.XPATH,'/html/body/div[1]/header/nav/div[1]/div[1]/div/div[2]/ul/li[2]/div[2]/div[3]/ul/li[1]/a')\n",
    "billion.click()\n",
    "time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3766be2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "'/html/body/div[1]/header/nav/div[1]/div[1]/div/div[2]/ul/li[2]/div[2]/div[3]/ul/li[1]/a')\n",
    "billionaires.click()\n",
    "time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f62cb431",
   "metadata": {},
   "outputs": [],
   "source": [
    "Rank=[]\n",
    "name=[]\n",
    "net_worth=[]\n",
    "Age=[]\n",
    "Citizenship=[]\n",
    "source=[]\n",
    "Industries=[]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf73ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "table=driver.find_elements(By.XPATH,'//div[@class=\"TableRow_row__L-0Km\"]')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "129364c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome()\n",
    "driver.get('http://www.forbes.com/')\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a008fd29",
   "metadata": {},
   "outputs": [],
   "source": [
    "billionaires=driver.find_element(By.XPATH,'/html/body/div[1]/header/nav/div[1]/div[1]/div/div[2]/ul/li[2]/div[2]/div[3]/ul/li[1]/a')\n",
    "billionaires.click()\n",
    "time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "640177a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Rank=[]\n",
    "name=[]\n",
    "net_worth=[]\n",
    "Age=[]\n",
    "Citizenship=[]\n",
    "source=[]\n",
    "Industries=[]\n",
    "\n",
    "\n",
    "rank_tag=driver.find_elements(By.XPATH,'//div[@class=\"TableRow_row__L-0Km\"]/div[1]/div')\n",
    "try:\n",
    "    for tag in rank_tag:\n",
    "        Rank.append(tag.text)\n",
    "except NoSuchElementException:\n",
    "    Rank.append('_')\n",
    "\n",
    "name_tag=driver.find_elements(By.XPATH,'//div[@class=\"TableRow_row__L-0Km\"]/div[2]')\n",
    "try:\n",
    "    for tag in name_tag:\n",
    "        name.append(tag.text)\n",
    "except NoSuchElementException:\n",
    "        name.append('_')\n",
    "\n",
    "net_worthtag=driver.find_elements(By.XPATH,'//div[@class=\"TableRow_row__L-0Km\"]/div[3]')\n",
    "try:\n",
    "    for tag in net_worthtag:\n",
    "        net_worth.append(tag.text)\n",
    "except NoSuchElementException: \n",
    "    net_worth.append('_')\n",
    "\n",
    "\n",
    "age_tag=driver.find_elements(By.XPATH,'//div[@class=\"TableRow_row__L-0Km\"]/div[4]')\n",
    "try:\n",
    "    for tag in age_tag:\n",
    "        Age.append(tag.text)\n",
    "except NoSuchElementException:\n",
    "    Age.append('_')\n",
    "    \n",
    "citizenship_tag=driver.find_elements(By.XPATH,'//div[@class=\"TableRow_row__L-0Km\"]/div[5]')\n",
    "try:\n",
    "    for tag in citizenship_tag:\n",
    "        Citizenship.append(tag.text)\n",
    "except NoSuchElementException:\n",
    "    Citizenship.append('_')\n",
    "    \n",
    "source_tag=driver.find_elements(By.XPATH,'//div[@class=\"Table_dataCell__2QCve\"]/span')\n",
    "for tag in source_tag:\n",
    "    source.append(tag.text)\n",
    "    \n",
    "industry_tag=driver.find_elements(By.XPATH,'//div[@class=\"TableRow_row__L-0Km\"]/div[7]/div')\n",
    "try:\n",
    "    for tag in industry_tag:\n",
    "        Industries.append(tag.text)\n",
    "except NoSuchElementException:\n",
    "    Industries.append('_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e3c4376",
   "metadata": {},
   "outputs": [],
   "source": [
    "Billionaires=pd.DataFrame({'Rank':Rank,'Name':name,'Net Worth':net_worth,'Age':Age,'Citizenship':Citizenship,'Source':source,'Industry':Industries})\n",
    "Billionaires"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c32d4c2",
   "metadata": {},
   "source": [
    "Write a program to extract at least 500 Comments, Comment upvote and time when comment was postedfrom any YouTube Video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce70886",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome()\n",
    "driver.get('https://www.youtube.com/watch?v=sNbGU_I9HWw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ddaa5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for comments in range(100):\n",
    "    driver.execute_script(\"window.scrollBy(0,500)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7047b825",
   "metadata": {},
   "outputs": [],
   "source": [
    "comments=[]\n",
    "Time=[]\n",
    "i=0\n",
    "comment=driver.find_elements(By.ID,'content-text')\n",
    "for tag in comment:\n",
    "    if i>=500:\n",
    "        break\n",
    "    else:\n",
    "        try:\n",
    "            result=tag.text\n",
    "            comments.append(result)\n",
    "            i+=1\n",
    "        except NoSuchElementException:\n",
    "            comments.append('-')\n",
    "len(comments)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b66b91cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(40):\n",
    "    driver.execute_script(\"window.scrollBy(0,500)\")\n",
    "    time=driver.find_elements(By.XPATH,'//a[@class=\"yt-simple-endpoint style-scope yt-formatted-string\"]')\n",
    "    for tag in comment:\n",
    "        if i>=500:\n",
    "            break\n",
    "        else:\n",
    "            result=tag.text\n",
    "            Time.append(result)\n",
    "            i+=1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0222e2fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({'Comments':comments,'Time':Time})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ad6e373",
   "metadata": {},
   "source": [
    "9. Write a python program to scrape a data for all available Hostels from https://www.hostelworld.com/ in“London” location. You have to scrape hostel name, distance from city centre, ratings, total reviews, overallreviews, privates from price, dorms from price, facilities and property description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "49612e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome()\n",
    "driver.get(\"https://www.hostelworld.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a493889e",
   "metadata": {},
   "outputs": [],
   "source": [
    "search=driver.find_element(By.XPATH,'/html/body/div[3]/div/div/div[2]/div[2]/div[2]/div/div/div/div[1]/div[1]/div/div[2]/input')\n",
    "search.send_keys('London')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "3f808336",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_button=driver.find_element(By.XPATH,'/html/body/div[3]/div/div/div[2]/div[2]/div[2]/div/div/div/div[5]/button[2]')\n",
    "search_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fead4f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.common.exceptions import ElementNotInteractableException\n",
    "URLS=[]\n",
    "start=0\n",
    "end=4\n",
    "\n",
    "for page in range (start,end):\n",
    "    url_tag=driver.find_elements(By.XPATH,'//a[@data-v-774cba8c]')\n",
    "    for tag in url_tag:     \n",
    "        URLS.append(tag.get_attribute('href'))\n",
    "try:\n",
    "    next_button=driver.find_element(By.XPATH,'//button[@data-v-6686d382][2]') \n",
    "    next_button.click()\n",
    "except ElementNotInteractableException as e:\n",
    "    print('Exception raised:',e)\n",
    "    next_button1=driver.fint_element(By.XPATH,'/html/body/div[3]/div/div/div[2]/div[2]/div[1]/div/div/div[7]/div/button[2]')\n",
    "    next_button1.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71cd55c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Names=[]\n",
    "Facilities=[]\n",
    "Description=[]\n",
    "Ratings=[]\n",
    "Total_reviews=[]\n",
    "Overallreviews=[]\n",
    "Distance=[]\n",
    "privateprices=[]\n",
    "dormsprices=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "014673c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for url in URLS:\n",
    "    driver.get(url)\n",
    "    time.sleep(10)\n",
    "\n",
    "    try:\n",
    "        name_tag=driver.find_elements(By.XPATH,'//h1[@class=\"name title-4-bld\"]')\n",
    "        Names.append(name_tag[0].text if name_tag else '_')\n",
    "    except NoSuchElementException:\n",
    "        Names.append('_')\n",
    "        \n",
    "    try:\n",
    "        facility_tag=driver.find_elements(By.XPATH,'//ul[@class=\"facilities\"]/li[2]/span')\n",
    "        Facilities.append(facility_tag[0].text if facility_tag else '_')\n",
    "    except NoSuchElementException:\n",
    "         Facilities.append('_')\n",
    "            \n",
    "    try:\n",
    "        description_tag=driver.find_elements(By.XPATH,'//p[@class=\"text line-clamp\"]')\n",
    "        Description.append(description_tag[0].text if description_tag else '_')\n",
    "    except NoSuchElementException:\n",
    "        Description.append('_')\n",
    "        \n",
    "\n",
    "    try:\n",
    "        rating_tag=driver.find_elements(By.XPATH,'//div[@class=\"rating-container collapsed\"]/div[1]/div[1]/div[1]/span[1]')\n",
    "        Ratings.append(rating_tag[0].text if rating_tag else '_')\n",
    "    except NoSuchElementException:\n",
    "        Ratings.append('_')\n",
    "        \n",
    "    try:\n",
    "        totalreview_tag=driver.find_elements(By.XPATH,'//div[@class=\"rating-container collapsed\"]/div[1]/div[1]/div[2]/span')\n",
    "        Total_reviews.append(totalreview_tag[0].text if totalreview_tag else '_')\n",
    "    except NoSuchElementException:\n",
    "        Total_reviews.append('_')\n",
    "        \n",
    "    try:\n",
    "        overallreview_tag=driver.find_elements(By.XPATH,'//div[@class=\"rating-container collapsed\"]/div[1]/div[1]/div[1]/span[2]')\n",
    "        Overallreviews.append(overallreview_tag[0].text if overallreview_tag else '_')\n",
    "    except NoSuchElementException:\n",
    "        Overallreviews.append('_')\n",
    "        \n",
    "    try:\n",
    "        privateprice_tag=driver.find_elements(By.XPATH,'//div[@data-v-c8d46c14]/div/div[2]/div[2]/div[3]/div[1]/div[3]')\n",
    "        privateprices.append(privateprice_tag[0].text if privateprice_tag else '_')\n",
    "    except NoSuchElementException:\n",
    "        privateprices.append('_')\n",
    "        \n",
    "        \n",
    "    try:\n",
    "        dormsprice_tag=driver.find_elements(By.XPATH,'//div[@data-v-c8d46c14]/div[2]/div[1]/div[2]/div[3]/div[1]/div[3]')\n",
    "        dormsprices.append(dormsprice_tag[0].text if dormsprice_tag else '_')\n",
    "    except NoSuchElementException:\n",
    "        dormsprices.append('_')\n",
    "    \n",
    "    try:\n",
    "        distance_tag=driver.find_elements(By.XPATH,'//li[@class=\"city-center\"]')\n",
    "        for tag in distance_tag:    \n",
    "            Distance.append(tag.text)\n",
    "    except NoSuchElementException:\n",
    "        Distance.append('_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a33237e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Distances=[i.split()[0] for i in Distance]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fdcaab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Hostel=pd.DataFrame({'Hostel name':Names,'Distance from CityCentre(KM)':Distances,'Ratings':Ratings,'Total Reviews':Total_reviews,'Overall Reviews':Overallreviews,'Privates from Price':privateprices,'Dorms from price':dormsprices,'Facilities':Facilities,'Property Description':Description})\n",
    "Hostel"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
